# COT5615
### Unit 1: Introduction
Motivating examples. Using Julia, Jupyter, Markdown and basic latex formulas. No prior reading is needed.
[![Intro to Julia](https://img.youtube.com/vi/8h8rQyEpiZA/0.jpg)](https://www.youtube.com/watch?v=8h8rQyEpiZA)

### Unit 2: Vectors (week 2)
From [VMLS]: 1.1 Vectors, 1.2 Vector addition, 1.3 Scalar-vector Multiplication, 1.4 Inner Product, 1.5 Complexity of vector computations, 2.1 Linear Functions, 2.2 Taylor approximation, C.1.2 Scalar-valued function of a vector, C.1.3 Vector-valued function of a vector.  
From [3B1B]:  
[![Vectors, what even are they? | Essence of linear algebra, chapter 1](https://img.youtube.com/vi/fNk_zzaMoSs/0.jpg)](https://www.youtube.com/watch?v=fNk_zzaMoSs)

### Unit 3: Using Vectors (week 3)
From [VMLS]: 3.1 Norm, 3.2 Distance, 3.3 Standard deviation, 3.4 Angle, 4.1 Clustering, 4.2 A clustering objective, 4.3 The k-means Algorithm.  
From [3B1B]:  
[![But what is a Neural Network? | Deep learning, chapter 1](https://img.youtube.com/vi/aircAruvnKk/0.jpg)](https://www.youtube.com/watch?v=aircAruvnKk) 

[![Gradient descent, how neural networks learn | Deep learning, chapter 2](https://img.youtube.com/vi/IHZwWFHWa-w/0.jpg)](https://www.youtube.com/watch?v=IHZwWFHWa-w) 

[![What is backpropagation really doing? | Deep learning, chapter 3](https://img.youtube.com/vi/Ilg3gGewQ5U/0.jpg)](https://www.youtube.com/watch?v=Ilg3gGewQ5U) 

[![Backpropagation calculus | Deep learning, chapter 4](https://img.youtube.com/vi/Ilg3gGewQ5U/0.jpg)](https://www.youtube.com/watch?v=tIeHLnjs5U8)

