\section{Linear functions}
\subsection{Linear functions} 
$f : R^n \to R$ means f is a function mapping n-vectors to numbers\\
\textit{Superposition \& linearity}: 
$f(\alpha x + \beta y) = \alpha f(x) + \beta f(y)$\\
\textbullet $ f(\alpha_1 x_1 +...+ \alpha_k x_k) = \alpha_1 f(x_1)+...+ \alpha_k f(x_k)$\\
A function that satisfies superposition is called \textit{linear}\\
\textbf{Linear function satisfies}\\
\textbullet \textit{Homogeneity}: For any n-vector x and any scalar $\alpha, f(\alpha x) = \alpha f(x)$ \\
\textbullet \textit{Additivity}: For any n-vectors x and y, $f(x + y) = f(x) + f(y)$\\
\textbf{Affine functions}
$f:R_n \to R$ is affine if and only if it can be expressed as $f(x) = a^Tx + b$ for some n-vector a and scalar b, which is sometimes called the \textit{offset}\\
\textbullet Any \textit{affine} scalar-valued function satisfies the following variation on the super-position property:
$f(\alpha x + \beta y) = \alpha f(x) + \beta f(y)$, where $\alpha + \beta = 1$

\subsection{Taylor approximation}
The (first-order) Taylor approximation of f near (or at) the point z:\\
\begin{scriptsize}
$\hat{f}(x)= f(z) + \frac{\partial f}{\partial x_1}(z)(x_1 - z_1) + ... +  \frac{\partial f}{\partial x_n}(z)(x_n - z_n)$
\end{scriptsize}\\
Alternatively,
$\hat{f}(x)=f(z)+ \nabla f(z)^T(x-z)$
\subsection{Regression model}
\textit{Regression model} is (the affine function of x) $\hat{y} = x^T \beta + v$
