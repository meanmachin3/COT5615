\section{Vectors}
\subsection*{Vectors}
\textbullet An ordered finite list of numbers.\\
\textbullet Block or stacked vectors($a = [b, c, d]$), Subvectors ($a_{r:s} = (a_r,...,a_s)$), Zero vectors (all elements equal to zero), Unit vectors(($e_i = 1$)), Ones vector($1_n$) \& Sparsity($nnz(x)$)

\subsection*{Vector addition}
\textbullet \textit{Commutative}: $a + b = b + a$\\
\textbullet \textit{Associative}: $(a + b) + c = a + (b + c)$\\
\textbullet $a+0 = 0+a = a$\\
\textbullet $a - a = 0$
\subsection{Scalar-vector multiplication}
$(-2)(1, 9, 6)=(-2, -18, -12)$\\
\textbullet \textit{Commutative}: $\alpha a = a \alpha$\\
\textbullet \textit{Left-distributive}: $(\beta + \gamma)a = \beta a + \gamma a$\\
\textbullet \textit{Right-distributive}: $a(\beta + \gamma) = a\beta + a\gamma $ \\

Linear combinations: $\beta_1 a_1 + ... + \beta_m a_m$\\
\textbullet With Unit vectors: $b = b_1 e_1 +...+ b_n e_n$ \\
\textbullet If $\beta_1 +...+ \beta_m = 1$, linear combination is said to be \textit{affine combination}

\subsection{Inner product}
$a^T b = a_1 b_1 +a_2 b_2 +...+ a_n b_n$
\textbf{Properties}:\\
\textbullet \textit{Commutativity}:$a^T b = b^T a$\\
\textbullet \textit{Scalar multiplication Associativity}:\\ $(\gamma a)^T b = \gamma(a^T b)$\\
\textbullet {Vector addition Distributivity}:\\
$(a + b)^T c = a^T c + b^T c.$

\textbf{General examples}:\\
\textbullet Unit vector: $e_i^T a = a_i$ \\
\textbullet Sum: $\textbf{1}^T a = a^1 + ... + a^n$ \\
\textbullet Average: $(\textbf{1}/n)^T a=(a^1+...+a^n)/n$\\ 
\textbullet Sum of squares: $a^Ta = a^2_1 +...+a^2_n$\\
\textbullet Selective sum: If $b_i = 1 or 0,$ \textit{$b^Ta$} is the sum of elements for which $b_i = 1$,

\textbf{Block vectors}\\
$a^T b = a_1^T b_1 + ... + a_k^T b_k$

\subsection{Complexity of vector computations}
\textbullet \textit{Space}:  8n bytes\\
\textbullet \textit{Complexity of vector operations}: $x^Ty=2n-1$ flops ($n$ scalar multiplications and $n-1$ scalar additions)\\
\textbullet \textit{Complexity of sparse vector operations}: If x is sparse, then computing $ax$ requires \textbf{nnz}(x) flops, If x and y are sparse, computing x + y requires no more than min{\textbf{nnz}(x), \textbf{nnz}(y)}. computing $x_T y$ requires no more than 2 min{\textbf{nnz}(x), \textbf{nnz}(y)} flops
